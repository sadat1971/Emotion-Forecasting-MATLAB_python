{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for TF-2 D-BLSTM network.\n",
    "\n",
    "\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from keras.utils import np_utils\n",
    "import keras    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()  #create the object logo for doing the leave-oen-subject-out cross validation\n",
    "grp = numpy.loadtxt(\"Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/speaker_group.csv\", delimiter=\",\")\n",
    "data=numpy.loadtxt('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/time_data_2_step_forecast.csv',delimiter=\",\")\n",
    "Y=numpy.loadtxt('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/label_2_step_forecast.csv',delimiter=\",\")\n",
    "# we have to reshape the data for using it in LSTM/BLSTM network\n",
    "A=data.reshape((1763,50,895))\n",
    "#code for BLSTM model\n",
    "F2con={} #save the confusion matrix\n",
    "F2ACC={} #save the accuracy or weighted recall\n",
    "F2WR={}\n",
    "F2UWR={} #save the unweighted recall\n",
    "F=0\n",
    "\n",
    "F2predict={} #save the predicted result\n",
    "F2test={} # save the actual test GT labels\n",
    "F2_modelpred={}  #save the predicted softmax labels\n",
    "for train, test in logo.split(A, Y, grp):\n",
    "    label_train=np_utils.to_categorical(Y[train])\n",
    "    # Set callback functions to early stop training and save the best model so far\n",
    "    callbacks= [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(50, 895)))  # the masking layer will ignore the masked o's\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Bidirectional(LSTM(128)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))##\n",
    "    #model.add(Dense(256,activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)   \n",
    "    sgd=keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    adagrad=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    history=model.fit(A[train], label_train,  epochs=50, validation_split=0.33, callbacks=callbacks, batch_size=128, verbose=1)\n",
    "    X_pred=model.predict(A[test,:])\n",
    "    Y_pred=numpy.argmax(X_pred, axis=1)\n",
    "    F2VAL_ACC[F]=history.history['val_acc']\n",
    "    F2TR_ACC[F]=history.history['acc']\n",
    "    F2con[F]=confusion_matrix(Y[test],Y_pred)\n",
    "    F2ACC[F]=accuracy_score(Y[test],Y_pred)\n",
    "    F2WR[F]=recall_score(Y[test],Y_pred, average='weighted') \n",
    "    F2UWR[F]=recall_score(Y[test],Y_pred, average='macro') \n",
    "    F2predict[F]=X_pred\n",
    "    F2test[F]=Y[test]\n",
    "    F2_modelpred[F]=Y_pred\n",
    "    print(F2con[F])\n",
    "    print(F2UWR[F])\n",
    "    print('score of F is {0}'.format(F))\n",
    "    model.save('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/Results/BLSTM/Saved_Models/M_{}/m_model_sp_{}.h5'.format(cs, F))\n",
    "    F=F+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###LSTM\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from keras.utils import np_utils\n",
    "import keras    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dropout\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "\n",
    "F2predict={}\n",
    "F2test={}\n",
    "F2_modelpred={}\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "grp = numpy.loadtxt(\"Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/speaker_group.csv\", delimiter=\",\")\n",
    "data=numpy.loadtxt('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/time_data_2_step_forecast.csv',delimiter=\",\")\n",
    "Y=numpy.loadtxt('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/CSV/label_2_step_forecast.csv',delimiter=\",\")\n",
    "A=data.reshape((1763,50,895))\n",
    "#code for BLSTM model\n",
    "F2con={}\n",
    "F2ACC={}\n",
    "F2WR={}\n",
    "F2UWR={}\n",
    "F=0\n",
    "\n",
    "for train, test in logo.split(A, Y, grp):\n",
    "    label_train=np_utils.to_categorical(Y[train])\n",
    "    # Set callback functions to early stop training and save the best model so far\n",
    "    callbacks= [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(50, 895)))\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Bidirectional(LSTM(128)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))##\n",
    "    #model.add(Dense(256,activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)   \n",
    "    sgd=keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    adagrad=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    history=model.fit(A[train], label_train,  epochs=50, validation_split=0.2, callbacks=callbacks, batch_size=128, verbose=1)\n",
    "    X_pred=model.predict(A[test,:])\n",
    "    Y_pred=numpy.argmax(X_pred, axis=1)\n",
    "    F2VAL_ACC[F]=history.history['val_acc']\n",
    "    F2TR_ACC[F]=history.history['acc']\n",
    "    F2con[F]=confusion_matrix(Y[test],Y_pred)\n",
    "    F2ACC[F]=accuracy_score(Y[test],Y_pred)\n",
    "    F2WR[F]=recall_score(Y[test],Y_pred, average='weighted') \n",
    "    F2UWR[F]=recall_score(Y[test],Y_pred, average='macro') \n",
    "    F2predict[F]=X_pred\n",
    "    F2test[F]=Y[test]\n",
    "    F2_modelpred[F]=Y_pred\n",
    "    print(F2con[F])\n",
    "    print(F2UWR[F])\n",
    "    print('score of F is {0}'.format(F))\n",
    "    model.save('Sadat/IEMOCAP_forcasting/sameframe/STATISTICAL/2_group/Results/LSTM/Saved_Models/M_{}/m_model_sp_{}.h5'.format(cs, F))\n",
    "    F=F+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
